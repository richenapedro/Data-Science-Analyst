{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82695,"databundleVersionId":9551816,"sourceType":"competition"}],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Misconceptions in Mathematics","metadata":{}},{"cell_type":"markdown","source":"## Introduction\nIn the evolving landscape of education, the ability to accurately identify and address misconceptions in student understanding is paramount. As multiple-choice questions (MCQs) remain a staple assessment tool, the challenge of tagging distractors—incorrect answers crafted to reflect specific misconceptions—has become increasingly complex. This competition invites participants to develop a Natural Language Processing (NLP) model powered by Machine Learning (ML) to predict the affinity between misconceptions and distractors in MCQs.\n\nThe primary objective of this project is to create a model that not only aligns with established misconceptions but also adapts to new, emerging ones. By analyzing a dataset of diagnostic questions, where each distractor is designed to capture a particular misconception, we aim to streamline the tagging process for educators. This will not only enhance the consistency of tagging across various human labelers but also improve the educational experience for students by ensuring that misconceptions are properly addressed.\n\nGiven the intricacies of mathematical content and the limitations of initial attempts using pre-trained language models, our approach will focus on refining the tagging process to produce high-quality, actionable insights. Throughout this notebook, we will engage in exploratory data analysis (EDA), feature engineering, and the development of classification models. We will evaluate our models using the Mean Average Precision @ 25 (MAP@25) metric to ensure their effectiveness in predicting relevant misconceptions.\n\nUltimately, this project aims to contribute to the understanding and management of misconceptions in education, paving the way for more effective teaching strategies and improved student outcomes. Let’s commence by loading the necessary libraries and the dataset for our analysis.","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n1. [Package Installation](#package-installation)\n2. [Library Imports](#library-imports)\n3. [Data Loading](#data-loading)\n4. [Initial Data Exploration](#initial-data-exploration)\n5. [Data Preparation](#data-preparation)\n6. [Data Visualization](#data-visualization)\n7. [Modeling](#modeling)\n8. [Model Evaluation](#model-evaluation)\n9. [Conclusion and Next Steps](#conclusion-and-next-steps)","metadata":{}},{"cell_type":"markdown","source":"## Package Installation\n\nIn this cell, we will install the necessary Python packages for our data analysis project. This step ensures that all the libraries required for data manipulation, visualization, and natural language processing are available in our environment. We will use the `pip` command to install the following libraries:\n\n- **NumPy**: A library for numerical calculations and array manipulation.\n- **Pandas**: A powerful library for data manipulation and analysis, particularly useful for working with structured data.\n- **Matplotlib**: A plotting library for creating static, animated, and interactive visualizations in Python.\n- **Seaborn**: A statistical data visualization library based on Matplotlib that provides a high-level interface for creating attractive graphics.\n- **Scikit-learn**: A machine learning library that provides simple and efficient tools for data mining and data analysis.\n- **Torch**: A deep learning framework that provides a flexible and efficient platform for building neural networks.\n- **Transformers**: A library from Hugging Face that provides pre-trained models and tools for natural language processing tasks.","metadata":{}},{"cell_type":"code","source":"# List of required libraries\nrequired_libraries = [\n    'numpy',         \n    'pandas',        \n    'matplotlib',    \n    'seaborn',       \n    'scikit-learn',  \n    'torch',         \n    'transformers',\n    'imbalanced-learn'\n]\n\ndef install(package):\n    \"\"\"Install the package using pip in a Jupyter Notebook.\"\"\"\n    print(f\"Installing {package}...\")\n    # Use the Jupyter magic command for installation\n    get_ipython().system(f'pip install {package}')\n\ndef check_libraries(libraries):\n    \"\"\"Check if the libraries are installed and install them if necessary.\"\"\"\n    missing_libraries = []\n\n    for library in libraries:\n        try:\n            __import__(library)\n        except ImportError:\n            missing_libraries.append(library)\n        except Exception as e:\n            # Captura outros erros que podem ocorrer durante a importação\n            print(f\"Error importing {library}: {e}\")\n            missing_libraries.append(library)\n\n    if missing_libraries:\n        print(f\"The following libraries are missing: {', '.join(missing_libraries)}\")\n        print(\"Starting installation...\")\n\n        installation_success = True  # Flag to track installation success\n\n        for library in missing_libraries:\n            try:\n                install(library)\n                print(f\"{library} installed successfully.\")\n            except Exception as e:\n                print(f\"Failed to install {library}: {e}\")\n                installation_success = False  # Mark as failed if there was an error\n\n        # Check again if the libraries were installed\n        for library in missing_libraries:\n            try:\n                __import__(library)\n            except ImportError:\n                print(f\"Error: {library} was not installed correctly.\")\n                installation_success = False  # Mark as failed if still missing\n\n        # Final message based on installation success\n        if installation_success:\n            print(\"All libraries were installed successfully.\")\n        else:\n            print(\"Some libraries were not installed correctly.\")\n    else:\n        print(\"All libraries are already installed.\")\n\nif __name__ == \"__main__\":\n    check_libraries(required_libraries)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:05.036598Z","iopub.execute_input":"2024-10-01T12:57:05.037097Z","iopub.status.idle":"2024-10-01T12:57:34.389219Z","shell.execute_reply.started":"2024-10-01T12:57:05.037054Z","shell.execute_reply":"2024-10-01T12:57:34.387402Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"The following libraries are missing: scikit-learn, imbalanced-learn\nStarting installation...\nInstalling scikit-learn...\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nscikit-learn installed successfully.\nInstalling imbalanced-learn...\nRequirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.12.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.14.1)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.5.0)\nimbalanced-learn installed successfully.\nError: scikit-learn was not installed correctly.\nError: imbalanced-learn was not installed correctly.\nSome libraries were not installed correctly.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Library Imports <a name=\"library-imports\"></a>\nIn this cell, we will import all the necessary libraries that we will use throughout the analysis. This includes libraries for data manipulation, visualization, and machine learning.","metadata":{}},{"cell_type":"code","source":"# Standard Libraries\nimport requests\nimport warnings\nfrom IPython.display import display\n\n# Data Science Libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Machine Learning Libraries\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n\n# Deep Learning Libraries\nimport torch\nfrom torch.utils.data import DataLoader\n\n# Transformers Library\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.394010Z","iopub.execute_input":"2024-10-01T12:57:34.394603Z","iopub.status.idle":"2024-10-01T12:57:34.406437Z","shell.execute_reply.started":"2024-10-01T12:57:34.394549Z","shell.execute_reply":"2024-10-01T12:57:34.405315Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading <a name=\"data-loading\"></a>\nHere, we will load the dataset containing information about Misconceptions in Mathematics and related factors. We will examine the structure of the data and check for any initial issues such as missing values.","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\n\n# Reading the CSV files\ntrain_df = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv')\ntest_df = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv')\nmiss_df = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv')\nsample_df = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.408146Z","iopub.execute_input":"2024-10-01T12:57:34.408591Z","iopub.status.idle":"2024-10-01T12:57:34.490749Z","shell.execute_reply.started":"2024-10-01T12:57:34.408552Z","shell.execute_reply":"2024-10-01T12:57:34.489725Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Display the first few rows of dataset to verify the reading\nprint(\"\\nMisconceptions in Mathematics Data:\")\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.492634Z","iopub.execute_input":"2024-10-01T12:57:34.493428Z","iopub.status.idle":"2024-10-01T12:57:34.509822Z","shell.execute_reply.started":"2024-10-01T12:57:34.493375Z","shell.execute_reply":"2024-10-01T12:57:34.508618Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\nMisconceptions in Mathematics Data:\n   QuestionId  ConstructId                                      ConstructName  \\\n0           0          856  Use the order of operations to carry out calcu...   \n1           1         1612  Simplify an algebraic fraction by factorising ...   \n2           2         2774            Calculate the range from a list of data   \n3           3         2377  Recall and use the intersecting diagonals prop...   \n4           4         3387  Substitute positive integer values into formul...   \n\n   SubjectId                                        SubjectName CorrectAnswer  \\\n0         33                                             BIDMAS             A   \n1       1077                    Simplifying Algebraic Fractions             D   \n2        339  Range and Interquartile Range from a List of Data             B   \n3         88                       Properties of Quadrilaterals             C   \n4         67                          Substitution into Formula             A   \n\n                                        QuestionText            AnswerAText  \\\n0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n3  The angles highlighted on this rectangle with ...                  acute   \n4  The equation \\( f=3 r^{2}+3 \\) is used to find...               \\( 30 \\)   \n\n              AnswerBText            AnswerCText             AnswerDText  \\\n0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n3                  obtuse       \\( 90^{\\circ} \\)  Not enough information   \n4                \\( 27 \\)               \\( 51 \\)                \\( 24 \\)   \n\n   MisconceptionAId  MisconceptionBId  MisconceptionCId  MisconceptionDId  \n0               NaN               NaN               NaN            1672.0  \n1            2142.0             143.0            2142.0               NaN  \n2            1287.0               NaN            1287.0            1073.0  \n3            1180.0            1180.0               NaN            1180.0  \n4               NaN               NaN               NaN            1818.0  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Using shape to check the dimensions of the combined DataFrame\nprint(\"\\nShape of Combined Data:\", train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.513069Z","iopub.execute_input":"2024-10-01T12:57:34.513488Z","iopub.status.idle":"2024-10-01T12:57:34.523342Z","shell.execute_reply.started":"2024-10-01T12:57:34.513449Z","shell.execute_reply":"2024-10-01T12:57:34.522308Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"\nShape of Combined Data: (1869, 15)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Initial Data Exploration <a name=\"initial-data-exploration\"></a>\nIn this section, we will conduct an exploratory data analysis (EDA) to gain a deeper understanding of our dataset. This analysis is crucial as it lays the foundation for the subsequent steps in our data cleaning and preparation process. We will examine various aspects of the data, including data types, summary statistics, and the presence of any missing values.","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nmissing_values = train_df.isnull().sum()\nprint(\"Missing Values in Each Column:\\n\", missing_values)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.524807Z","iopub.execute_input":"2024-10-01T12:57:34.525224Z","iopub.status.idle":"2024-10-01T12:57:34.539238Z","shell.execute_reply.started":"2024-10-01T12:57:34.525185Z","shell.execute_reply":"2024-10-01T12:57:34.538118Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Missing Values in Each Column:\n QuestionId            0\nConstructId           0\nConstructName         0\nSubjectId             0\nSubjectName           0\nCorrectAnswer         0\nQuestionText          0\nAnswerAText           0\nAnswerBText           0\nAnswerCText           0\nAnswerDText           0\nMisconceptionAId    734\nMisconceptionBId    751\nMisconceptionCId    789\nMisconceptionDId    832\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check data types\ndata_types = train_df.dtypes\nprint(\"\\nData Types of Each Column:\\n\", data_types)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.540727Z","iopub.execute_input":"2024-10-01T12:57:34.541187Z","iopub.status.idle":"2024-10-01T12:57:34.553213Z","shell.execute_reply.started":"2024-10-01T12:57:34.541147Z","shell.execute_reply":"2024-10-01T12:57:34.551824Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"\nData Types of Each Column:\n QuestionId            int64\nConstructId           int64\nConstructName        object\nSubjectId             int64\nSubjectName          object\nCorrectAnswer        object\nQuestionText         object\nAnswerAText          object\nAnswerBText          object\nAnswerCText          object\nAnswerDText          object\nMisconceptionAId    float64\nMisconceptionBId    float64\nMisconceptionCId    float64\nMisconceptionDId    float64\ndtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"# Correcting data types\ntrain_df['QuestionId'] = train_df['QuestionId'].astype('category')  # Ensure QuestionId is int\ntrain_df['ConstructId'] = train_df['ConstructId'].astype('category')  # Ensure ConstructId is int\ntrain_df['SubjectId'] = train_df['SubjectId'].astype('category')  # Ensure SubjectId is int\ntrain_df['CorrectAnswer'] = train_df['CorrectAnswer'].astype(str)  # Ensure CorrectAnswer is str\ntrain_df['ConstructName'] = train_df['ConstructName'].astype(str)  # Ensure ConstructName is str\ntrain_df['SubjectName'] = train_df['SubjectName'].astype(str)  # Ensure SubjectName is str\ntrain_df['QuestionText'] = train_df['QuestionText'].astype(str)  # Ensure QuestionText is str\ntrain_df['AnswerAText'] = train_df['AnswerAText'].astype(str)  # Ensure AnswerAText is str\ntrain_df['AnswerBText'] = train_df['AnswerBText'].astype(str)  # Ensure AnswerBText is str\ntrain_df['AnswerCText'] = train_df['AnswerCText'].astype(str)  # Ensure AnswerCText is str\ntrain_df['AnswerDText'] = train_df['AnswerDText'].astype(str)  # Ensure AnswerDText is str\n\n# For misconceptions, since they can be NaN, we can convert them to integers but also allow NaN values\ntrain_df['MisconceptionAId'] = train_df['MisconceptionAId'].astype('category')  # Use 'Int64' to allow NaNs\ntrain_df['MisconceptionBId'] = train_df['MisconceptionBId'].astype('category')  # Use 'Int64' to allow NaNs\ntrain_df['MisconceptionCId'] = train_df['MisconceptionCId'].astype('category')  # Use 'Int64' to allow NaNs\ntrain_df['MisconceptionDId'] = train_df['MisconceptionDId'].astype('category')  # Use 'Int64' to allow NaNs\n\n# Check the corrected data types\nprint(\"\\nCorrected Data Types:\")\nprint(train_df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.555042Z","iopub.execute_input":"2024-10-01T12:57:34.555478Z","iopub.status.idle":"2024-10-01T12:57:34.583977Z","shell.execute_reply.started":"2024-10-01T12:57:34.555438Z","shell.execute_reply":"2024-10-01T12:57:34.582769Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"\nCorrected Data Types:\nQuestionId          category\nConstructId         category\nConstructName         object\nSubjectId           category\nSubjectName           object\nCorrectAnswer         object\nQuestionText          object\nAnswerAText           object\nAnswerBText           object\nAnswerCText           object\nAnswerDText           object\nMisconceptionAId    category\nMisconceptionBId    category\nMisconceptionCId    category\nMisconceptionDId    category\ndtype: object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preparation <a name=\"data-preparation\"></a>\nIn order to build effective machine learning models for our NLP competition, we must first ensure that our data is prepared thoroughly. The data preparation process is critical for achieving optimal model performance and involves several key steps.\n\nFirst, we need to handle any missing values that may exist in our dataset. This is essential to prevent any disruptions in the training process and to ensure that our model can learn from complete data. Next, we will encode categorical variables, which allows our machine learning algorithms to interpret the data correctly and make accurate predictions.\n\nAdditionally, we will split the dataset into training and testing sets. This division is crucial as it enables us to evaluate our model's performance on unseen data, helping us avoid overfitting and ensuring that our model generalizes well.\n\nWe will also analyze the distribution of question lengths to understand the complexity of the data we are working with. Understanding this distribution can provide insights into how to preprocess our text data effectively. Cleaning the text data is another vital step, as it enhances the quality of the input provided to the model, ultimately leading to improved predictions\n\nBelow is the code that implements these data preparation steps, creating prediction and test dataframes from our original dataset, and concatenating the relevant texts to form a complete input for our models.","metadata":{}},{"cell_type":"code","source":"def create_prediction_dataframe(df):\n    # Create a list to store the predictions\n    pred_list = []\n\n    # Add the questions and answers\n    for index, row in df.iterrows():\n        for answer in ['A', 'B', 'C', 'D']:\n            # Check if the current answer is equal to the correct answer\n            if answer != row['CorrectAnswer']:\n                pred_list.append({\n                    'QuestionId': row['QuestionId'],\n                    'Answer': answer,\n                    'QuestionText': row['QuestionText'],\n                    'MisconceptionId': row[f'Misconception{answer}Id'],\n                    'AnswerText': row[f'Answer{answer}Text'] \n                })\n\n    # Create a dataframe from the list\n    pred_data = pd.DataFrame(pred_list)\n    return pred_data\n\n\ndef create_test_dataframe(df):\n    # Create a list to store the test data\n    test_list = []\n\n    # Add the questions and answers\n    for index, row in df.iterrows():\n        for answer in ['A', 'B', 'C', 'D']:\n            test_list.append({\n                'QuestionId': row['QuestionId'],\n                'Answer': answer,\n                'QuestionText': row['QuestionText'],\n                'AnswerText': row[f'Answer{answer}Text'] \n            })\n\n    # Create a dataframe from the list\n    test_data = pd.DataFrame(test_list)\n    return test_data\n\n\n# Create Prediction DataFrame for the training set\ntrain_pred_data = create_prediction_dataframe(train_df)\n\ntrain_pred_data['QuestionAnswer'] = train_pred_data['QuestionText'] + train_pred_data['AnswerText']\ntrain_pred_data.dropna(inplace=True)\n\ntest_pred_data = create_test_dataframe(test_df)\n\ntest_pred_data['QuestionAnswer'] = test_pred_data['QuestionText'] + test_pred_data['AnswerText']\n\n# Display the resulting DataFrames\ndisplay(train_pred_data)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.585689Z","iopub.execute_input":"2024-10-01T12:57:34.586187Z","iopub.status.idle":"2024-10-01T12:57:34.916441Z","shell.execute_reply.started":"2024-10-01T12:57:34.586134Z","shell.execute_reply":"2024-10-01T12:57:34.915245Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"      QuestionId Answer                                       QuestionText  \\\n2              0      D  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...   \n3              1      A  Simplify the following, if possible: \\( \\frac{...   \n4              1      B  Simplify the following, if possible: \\( \\frac{...   \n5              1      C  Simplify the following, if possible: \\( \\frac{...   \n6              2      A  Tom and Katie are discussing the \\( 5 \\) plant...   \n...          ...    ...                                                ...   \n5602        1867      C  Tom and Katie are discussing congruence and si...   \n5603        1867      D  Tom and Katie are discussing congruence and si...   \n5604        1868      A  Jo and Paul are arguing about how to fully des...   \n5605        1868      C  Jo and Paul are arguing about how to fully des...   \n5606        1868      D  Jo and Paul are arguing about how to fully des...   \n\n      MisconceptionId              AnswerText  \\\n2              1672.0  Does not need brackets   \n3              2142.0               \\( m+1 \\)   \n4               143.0               \\( m+2 \\)   \n5              2142.0               \\( m-1 \\)   \n6              1287.0               Only\\nTom   \n...               ...                     ...   \n5602           2312.0      Both Tom and Katie   \n5603           2312.0      Neither is correct   \n5604            801.0                Only\\nJo   \n5605            801.0        Both Jo and Paul   \n5606             95.0      Neither is correct   \n\n                                         QuestionAnswer  \n2     \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \n3     Simplify the following, if possible: \\( \\frac{...  \n4     Simplify the following, if possible: \\( \\frac{...  \n5     Simplify the following, if possible: \\( \\frac{...  \n6     Tom and Katie are discussing the \\( 5 \\) plant...  \n...                                                 ...  \n5602  Tom and Katie are discussing congruence and si...  \n5603  Tom and Katie are discussing congruence and si...  \n5604  Jo and Paul are arguing about how to fully des...  \n5605  Jo and Paul are arguing about how to fully des...  \n5606  Jo and Paul are arguing about how to fully des...  \n\n[4370 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QuestionId</th>\n      <th>Answer</th>\n      <th>QuestionText</th>\n      <th>MisconceptionId</th>\n      <th>AnswerText</th>\n      <th>QuestionAnswer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>D</td>\n      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n      <td>1672.0</td>\n      <td>Does not need brackets</td>\n      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>A</td>\n      <td>Simplify the following, if possible: \\( \\frac{...</td>\n      <td>2142.0</td>\n      <td>\\( m+1 \\)</td>\n      <td>Simplify the following, if possible: \\( \\frac{...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>B</td>\n      <td>Simplify the following, if possible: \\( \\frac{...</td>\n      <td>143.0</td>\n      <td>\\( m+2 \\)</td>\n      <td>Simplify the following, if possible: \\( \\frac{...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>C</td>\n      <td>Simplify the following, if possible: \\( \\frac{...</td>\n      <td>2142.0</td>\n      <td>\\( m-1 \\)</td>\n      <td>Simplify the following, if possible: \\( \\frac{...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>A</td>\n      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n      <td>1287.0</td>\n      <td>Only\\nTom</td>\n      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5602</th>\n      <td>1867</td>\n      <td>C</td>\n      <td>Tom and Katie are discussing congruence and si...</td>\n      <td>2312.0</td>\n      <td>Both Tom and Katie</td>\n      <td>Tom and Katie are discussing congruence and si...</td>\n    </tr>\n    <tr>\n      <th>5603</th>\n      <td>1867</td>\n      <td>D</td>\n      <td>Tom and Katie are discussing congruence and si...</td>\n      <td>2312.0</td>\n      <td>Neither is correct</td>\n      <td>Tom and Katie are discussing congruence and si...</td>\n    </tr>\n    <tr>\n      <th>5604</th>\n      <td>1868</td>\n      <td>A</td>\n      <td>Jo and Paul are arguing about how to fully des...</td>\n      <td>801.0</td>\n      <td>Only\\nJo</td>\n      <td>Jo and Paul are arguing about how to fully des...</td>\n    </tr>\n    <tr>\n      <th>5605</th>\n      <td>1868</td>\n      <td>C</td>\n      <td>Jo and Paul are arguing about how to fully des...</td>\n      <td>801.0</td>\n      <td>Both Jo and Paul</td>\n      <td>Jo and Paul are arguing about how to fully des...</td>\n    </tr>\n    <tr>\n      <th>5606</th>\n      <td>1868</td>\n      <td>D</td>\n      <td>Jo and Paul are arguing about how to fully des...</td>\n      <td>95.0</td>\n      <td>Neither is correct</td>\n      <td>Jo and Paul are arguing about how to fully des...</td>\n    </tr>\n  </tbody>\n</table>\n<p>4370 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Modeling <a name=\"modeling\"></a>\nIn this section, we will build and evaluate machine learning models aimed at predicting instances of cyberbullying based on the textual content of tweets. Our primary objective is to select suitable algorithms, fit them to our training data, and assess their performance using a variety of metrics.\n\nTo initiate our modeling process, we first load and save a pre-trained BERT tokenizer and model. These components are essential for processing the textual data and transforming it into a format suitable for our machine learning algorithms.","metadata":{}},{"cell_type":"code","source":"model_typ = 'distilbert' #roberta, distilbert,t5,bert","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.917860Z","iopub.execute_input":"2024-10-01T12:57:34.918217Z","iopub.status.idle":"2024-10-01T12:57:34.923140Z","shell.execute_reply.started":"2024-10-01T12:57:34.918178Z","shell.execute_reply":"2024-10-01T12:57:34.922056Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def check_internet_connection(url='http://www.google.com', timeout=5):\n    try:\n        # Try to make a request to check the connection\n        requests.get(url, timeout=timeout)\n        return True\n    except requests.ConnectionError:\n        return False\n\n# Check if there is an internet connection\nif check_internet_connection():\n    print(\"Internet connection detected. Loading and saving the models and tokenizers.\")\n\n    # Load and save BERT\n    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=miss_df['MisconceptionId'].nunique())\n    bert_tokenizer.save_pretrained('./local_bert')\n    bert_model.save_pretrained('./local_bert')\n\n    # Load and save RoBERTa\n    roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n    roberta_model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=miss_df['MisconceptionId'].nunique())\n    roberta_tokenizer.save_pretrained('./local_roberta')\n    roberta_model.save_pretrained('./local_roberta')\n\n    # Load and save DistilBERT\n    distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n    distilbert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=miss_df['MisconceptionId'].nunique())\n    distilbert_tokenizer.save_pretrained('./local_distilbert')\n    distilbert_model.save_pretrained('./local_distilbert')\n\n    # Load and save T5\n    t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n    t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n    t5_tokenizer.save_pretrained('./local_t5')\n    t5_model.save_pretrained('./local_t5')\n\n    print(\"All models and tokenizers have been loaded and saved locally.\")\nelse:\n    print(\"No internet connection. The models and tokenizers will not be loaded.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:34.924452Z","iopub.execute_input":"2024-10-01T12:57:34.924770Z","iopub.status.idle":"2024-10-01T12:57:54.962207Z","shell.execute_reply.started":"2024-10-01T12:57:34.924734Z","shell.execute_reply":"2024-10-01T12:57:54.961122Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"No internet connection. The models and tokenizers will not be loaded.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next, we will load our training data, which consists of tweet texts and their corresponding labels indicating instances of cyberbullying. We split this data into training and validation sets to ensure that we can evaluate our model's performance on unseen data.","metadata":{}},{"cell_type":"code","source":"# Load the data\nX = train_pred_data['QuestionAnswer']\ny = train_pred_data['MisconceptionId'].astype(int)  # You can use a multi-label approach\n\n# Split into training and validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:54.963683Z","iopub.execute_input":"2024-10-01T12:57:54.964078Z","iopub.status.idle":"2024-10-01T12:57:54.976421Z","shell.execute_reply.started":"2024-10-01T12:57:54.964012Z","shell.execute_reply":"2024-10-01T12:57:54.975481Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"After that, we load the BERT tokenizer and model from our local directory to prepare for the tokenization of our data. Tokenization is a crucial step that converts the raw text into numerical representations that the model can understand.\n\nWe then proceed to tokenize our training and validation datasets, applying truncation and padding to ensure uniform input sizes.\n\nTo facilitate the training process, we create a custom dataset class that transforms our tokenized data into PyTorch tensors, which are necessary for model training.\n\nNext, we set up the training configurations, specifying parameters such as batch size, number of epochs, and logging options. These configurations will guide the training process.\n\nFinally, we initialize the Trainer class with our model and training arguments, and we proceed to train the model. After training, we evaluate its performance on the validation set.","metadata":{}},{"cell_type":"code","source":"if model_typ == 'roberta' or model_typ == 'all':\n    # Load the RoBERTa tokenizer and model from Hugging Face\n    tokenizer_roberta = RobertaTokenizer.from_pretrained('roberta-base')\n    model_roberta = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=miss_df['MisconceptionId'].nunique())\n\n    # Tokenization of the data\n    train_encodings_roberta = tokenizer_roberta(list(X_train), truncation=True, padding=True, max_length=128)\n    val_encodings_roberta = tokenizer_roberta(list(X_val), truncation=True, padding=True, max_length=128)\n\n    # Create PyTorch tensors\n    class CustomDatasetRoBERTa(torch.utils.data.Dataset):\n        def __init__(self, encodings, labels):\n            self.encodings = encodings\n            self.labels = labels.to_numpy()  # Convert to NumPy array\n\n        def __getitem__(self, idx):\n            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n            item['labels'] = torch.tensor(self.labels[idx])  # Use idx directly\n            return item\n\n        def __len__(self):\n            return len(self.labels)\n\n    train_dataset_roberta = CustomDatasetRoBERTa(train_encodings_roberta, y_train)\n    val_dataset_roberta = CustomDatasetRoBERTa(val_encodings_roberta, y_val)\n\n    # Training configurations\n    training_args_roberta = TrainingArguments(\n        output_dir='./results_roberta',\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        fp16=True,\n        num_train_epochs=3,\n        gradient_accumulation_steps=2,  # Para simular um tamanho de lote maior\n        logging_dir='./logs_roberta',\n        report_to=[\"none\"],\n    )\n\n    # Training\n    trainer_roberta = Trainer(\n        model=model_roberta,\n        args=training_args_roberta,\n        train_dataset=train_dataset_roberta,\n        eval_dataset=val_dataset_roberta\n    )\n\n    trainer_roberta.train()\n\n    # Evaluation\n    trainer_roberta.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:54.977945Z","iopub.execute_input":"2024-10-01T12:57:54.978389Z","iopub.status.idle":"2024-10-01T12:57:54.993431Z","shell.execute_reply.started":"2024-10-01T12:57:54.978348Z","shell.execute_reply":"2024-10-01T12:57:54.992251Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"if model_typ == 'distilbert' or model_typ == 'all':\n    # Load the DistilBERT tokenizer and model from Hugging Face\n    tokenizer_distilbert = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n    model_distilbert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=miss_df['MisconceptionId'].nunique())\n\n    # Tokenization of the data\n    train_encodings_distilbert = tokenizer_distilbert(list(X_train), truncation=True, padding=True, max_length=128)\n    val_encodings_distilbert = tokenizer_distilbert(list(X_val), truncation=True, padding=True, max_length=128)\n\n    # Create PyTorch tensors\n    class CustomDatasetDistilBERT(torch.utils.data.Dataset):\n        def __init__(self, encodings, labels):\n            self.encodings = encodings\n            self.labels = labels.to_numpy()  # Convert to NumPy array\n\n        def __getitem__(self, idx):\n            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n            item['labels'] = torch.tensor(self.labels[idx])  # Use idx directly\n            return item\n\n        def __len__(self):\n            return len(self.labels)\n\n    train_dataset_distilbert = CustomDatasetDistilBERT(train_encodings_distilbert, y_train)\n    val_dataset_distilbert = CustomDatasetDistilBERT(val_encodings_distilbert, y_val)\n\n    # Training configurations\n    training_args_distilbert = TrainingArguments(\n    output_dir='./results_distilbert',\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    fp16=True,\n    num_train_epochs=3,\n    gradient_accumulation_steps=2,  # Para simular um tamanho de lote maior\n    logging_dir='./logs_distilbert',\n    report_to=[\"none\"],\n    )\n\n    # Training\n    trainer_distilbert = Trainer(\n    model=model_distilbert,\n    args=training_args_distilbert,\n    train_dataset=train_dataset_distilbert,\n    eval_dataset=val_dataset_distilbert\n    )\n\n    trainer_distilbert.train()\n\n    # Evaluation\n    trainer_distilbert.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:57:54.997350Z","iopub.execute_input":"2024-10-01T12:57:54.997773Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='36' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 36/654 03:04 < 55:52, 0.18 it/s, Epoch 0.16/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"if model_typ == 't5' or model_typ == 'all':\n    # Load the T5 tokenizer and model from Hugging Face\n    tokenizer_t5 = T5Tokenizer.from_pretrained('t5-base')\n    model_t5 = T5ForConditionalGeneration.from_pretrained('t5-base')\n\n    # Prepare the data for T5, as it expects inputs in a specific format\n    train_encodings_t5 = tokenizer_t5(list(X_train), truncation=True, padding=True, max_length=128, return_tensors='pt')\n    val_encodings_t5 = tokenizer_t5(list(X_val), truncation=True, padding=True, max_length=128, return_tensors='pt')\n\n    # Create PyTorch tensors\n    class CustomDatasetT5(torch.utils.data.Dataset):\n        def __init__(self, encodings, labels):\n            self.encodings = encodings\n            self.labels = labels.to_numpy()  # Convert to NumPy array\n\n        def __getitem__(self, idx):\n            item = {key: val[idx] for key, val in self.encodings.items()}  # Use original tensors\n            item['labels'] = torch.tensor(self.labels[idx])  # Use idx directly\n            return item\n\n        def __len__(self):\n            return len(self.labels)\n\n    train_dataset_t5 = CustomDatasetT5(train_encodings_t5, y_train)\n    val_dataset_t5 = CustomDatasetT5(val_encodings_t5, y_val)\n\n    # Training configurations\n    training_args_t5 = TrainingArguments(\n        output_dir='./results_t5',\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        fp16=True,\n        num_train_epochs=3,\n        gradient_accumulation_steps=2,  # Para simular um tamanho de lote maior\n        logging_dir='./logs_t5',\n        report_to=[\"none\"],\n    )\n\n    # Training\n    trainer_t5 = Trainer(\n        model=model_t5,\n        args=training_args_t5,\n        train_dataset=train_dataset_t5,\n        eval_dataset=val_dataset_t5\n    )\n\n    trainer_t5.train()\n\n    # Evaluation\n    trainer_t5.evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if model_typ == 'bert' or model_typ == 'all':\n    # Load the BERT tokenizer and model from local directory\n    tokenizer_bert = BertTokenizer.from_pretrained('./local_bert')\n    model_bert = BertForSequenceClassification.from_pretrained('./local_bert', num_labels=miss_df['MisconceptionId'].nunique())\n\n    # Tokenization of the data\n    train_encodings_bert = tokenizer_bert(list(X_train), truncation=True, padding=True, max_length=128)\n    val_encodings_bert = tokenizer_bert(list(X_val), truncation=True, padding=True, max_length=128)\n\n    # Create PyTorch tensors\n    class CustomDataset(torch.utils.data.Dataset):\n        def __init__(self, encodings, labels):\n            self.encodings = encodings\n            self.labels = labels.to_numpy()  # Convert to NumPy array\n\n        def __getitem__(self, idx):\n            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n            item['labels'] = torch.tensor(self.labels[idx])  # Use idx directly\n            return item\n\n        def __len__(self):\n            return len(self.labels)\n\n    train_dataset_bert = CustomDataset(train_encodings_bert, y_train)\n    val_dataset_bert = CustomDataset(val_encodings_bert, y_val)\n\n    # Training configurations\n    training_args_bert = TrainingArguments(\n        output_dir='./results',\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        fp16=True,\n        num_train_epochs=3,\n        gradient_accumulation_steps=2,  # Para simular um tamanho de lote maior\n        logging_dir='./logs',\n        report_to=[\"none\"],\n    )\n\n    # # Training configurations\n    # training_args = TrainingArguments(\n    #     output_dir='./results',\n    #     per_device_train_batch_size=32,\n    #     per_device_eval_batch_size=32,\n    #     fp16=True,\n    #     num_train_epochs=12,\n    #     gradient_accumulation_steps=2,  # Para simular um tamanho de lote maior\n    #     logging_dir='./logs',\n    #     report_to=[\"none\"],\n    # )\n\n    # Training\n    trainer = Trainer(\n        model=model_bert,\n        args=training_args_bert,\n        train_dataset=train_dataset_bert,\n        eval_dataset=val_dataset_bert\n    )\n\n    trainer.train()\n\n    # Evaluation\n    trainer.evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By executing the above steps, we will successfully develop and evaluate our machine learning models, enabling us to predict instances of cyberbullying based on the textual content of tweets. This process not only enhances our understanding of the data but also provides valuable insights into the effectiveness of our chosen algorithm","metadata":{}},{"cell_type":"markdown","source":"## Model Evaluation <a name=\"model-evaluation\"></a>\nAfter building our models, it is crucial to evaluate their performance to determine how well they can predict instances of cyberbullying based on the textual content of tweets. In this section, we will assess each model using various metrics, including accuracy, precision, recall, and F1-score. We will compare the predictions against the actual outcomes to gain insights into the effectiveness of our models.","metadata":{}},{"cell_type":"markdown","source":"### Evaluation Steps\n- Extract Predictions: We will first extract the question-answer pairs from the test dataset and create a unique identifier for each question-answer combination.\n- Tokenization: The test dataset will be tokenized using the same BERT tokenizer that we used for training, ensuring consistency in input format.\n- Custom Dataset Class: We will define a custom dataset class for the test data to facilitate batch processing during evaluation.\n- DataLoader: A DataLoader will be created for the test dataset to allow for easy iteration through the data in batches.\n- Make Predictions: We will use the trained model to make predictions on the test dataset, retrieving the top predictions for each input.\n- Format Predictions: Finally, we will format the predictions for submission and save them in a CSV file.\n\nBelow is the code that implements these evaluation steps:","metadata":{}},{"cell_type":"code","source":"# Extract question-answer pairs from the test dataset\nquestion_answers = test_pred_data['QuestionAnswer']\n\n# Create 'question_id' by combining 'QuestionId' and 'Answer'\ntest_pred_data['question_id'] = test_pred_data['QuestionId'].astype(str) + '_' + test_pred_data['Answer'].astype(str)\n\n# Tokenize the test dataset\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntest_encodings = tokenizer(list(question_answers), truncation=True, padding=True, max_length=128)\n\n# Custom dataset class for the test data\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        # Convert each encoding to a tensor\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        return item\n\n    def __len__(self):\n        # Return the number of input samples\n        return len(self.encodings['input_ids'])\n\n# Create DataLoader for the test dataset\ntest_dataset = CustomDataset(test_encodings)\ntest_loader = DataLoader(test_dataset, batch_size=8)\n\n# Make predictions\npredictions = []\nquestion_ids = []  # Store corresponding question IDs\nwith torch.no_grad():  # Disable gradient calculation during evaluation\n    for batch_idx, batch in enumerate(test_loader):\n        outputs = model(**batch)\n        logits = outputs.logits\n        # Get probabilities using softmax\n        probs = torch.softmax(logits, dim=1)\n        # Retrieve indices of the top 25 predictions\n        top_k = torch.topk(probs, k=25, dim=1).indices  # shape: (batch_size, 25)\n        predictions.append(top_k)\n\n        # Collect corresponding question IDs for each batch\n        start_idx = batch_idx * test_loader.batch_size\n        end_idx = start_idx + len(batch['input_ids'])\n        question_ids.extend(test_pred_data['question_id'].iloc[start_idx:end_idx])\n\n# Format the predictions for submission\nfinal_predictions = []\nfor batch_preds in predictions:\n    for pred in batch_preds:\n        # Append the top 25 misconception IDs as a space-separated string\n        final_predictions.append(' '.join(map(str, pred.numpy())))\n\n# Create a DataFrame for the submission file\nsubmission_df = pd.DataFrame({\n    'QuestionId_Answer': question_ids,\n    'MisconceptionId': final_predictions\n})\n\n# Save the DataFrame as a CSV file\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By following the steps outlined above, we can effectively evaluate our models and produce a submission file containing the top predictions for each question-answer pair. This evaluation process allows us to quantify the performance of our models and make necessary adjustments or improvements based on the results. The metrics derived from the evaluation will provide valuable insights into the model's strengths and weaknesses in predicting instances of cyberbullying.","metadata":{}},{"cell_type":"markdown","source":"## Conclusion and Next Steps <a name=\"conclusion-and-next-steps\"></a>\n","metadata":{}},{"cell_type":"markdown","source":"By continuing to refine our models and approaches, we can contribute to creating a safer online environment for all users.","metadata":{}}]}