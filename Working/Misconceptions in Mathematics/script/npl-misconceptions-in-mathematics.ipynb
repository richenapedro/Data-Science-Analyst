{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Misconceptions in Mathematics"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","In the evolving landscape of education, the ability to accurately identify and address misconceptions in student understanding is paramount. As multiple-choice questions (MCQs) remain a staple assessment tool, the challenge of tagging distractors—incorrect answers crafted to reflect specific misconceptions—has become increasingly complex. This competition invites participants to develop a Natural Language Processing (NLP) model powered by Machine Learning (ML) to predict the affinity between misconceptions and distractors in MCQs.\n","\n","The primary objective of this project is to create a model that not only aligns with established misconceptions but also adapts to new, emerging ones. By analyzing a dataset of diagnostic questions, where each distractor is designed to capture a particular misconception, we aim to streamline the tagging process for educators. This will not only enhance the consistency of tagging across various human labelers but also improve the educational experience for students by ensuring that misconceptions are properly addressed.\n","\n","Given the intricacies of mathematical content and the limitations of initial attempts using pre-trained language models, our approach will focus on refining the tagging process to produce high-quality, actionable insights. Throughout this notebook, we will engage in exploratory data analysis (EDA), feature engineering, and the development of classification models. We will evaluate our models using the Mean Average Precision @ 25 (MAP@25) metric to ensure their effectiveness in predicting relevant misconceptions.\n","\n","Ultimately, this project aims to contribute to the understanding and management of misconceptions in education, paving the way for more effective teaching strategies and improved student outcomes. Let’s commence by loading the necessary libraries and the dataset for our analysis."]},{"cell_type":"markdown","metadata":{},"source":["## Table of Contents\n","1. [Package Installation](#package-installation)\n","2. [Library Imports](#library-imports)\n","3. [Data Loading](#data-loading)\n","4. [Initial Data Exploration](#initial-data-exploration)\n","5. [Data Preparation](#data-preparation)\n","6. [Data Visualization](#data-visualization)\n","7. [Modeling](#modeling)\n","8. [Model Evaluation](#model-evaluation)\n","9. [Conclusion and Next Steps](#conclusion-and-next-steps)"]},{"cell_type":"markdown","metadata":{},"source":["## Package Installation\n","\n","In this cell, we will install the necessary Python packages for our data analysis project. This step ensures that all the libraries required for data manipulation, visualization, and natural language processing are available in our environment. We will use the `pip` command to install the following libraries:\n","\n","- **NumPy**: A library for numerical calculations and array manipulation.\n","- **Pandas**: A powerful library for data manipulation and analysis, particularly useful for working with structured data.\n","- **Matplotlib**: A plotting library for creating static, animated, and interactive visualizations in Python.\n","- **Seaborn**: A statistical data visualization library based on Matplotlib that provides a high-level interface for creating attractive graphics.\n","- **Scikit-learn**: A machine learning library that provides simple and efficient tools for data mining and data analysis.\n","- **Torch**: A deep learning framework that provides a flexible and efficient platform for building neural networks.\n","- **Transformers**: A library from Hugging Face that provides pre-trained models and tools for natural language processing tasks."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.057760Z","iopub.status.busy":"2024-09-30T20:45:20.056512Z","iopub.status.idle":"2024-09-30T20:45:20.070528Z","shell.execute_reply":"2024-09-30T20:45:20.069565Z","shell.execute_reply.started":"2024-09-30T20:45:20.057710Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["All libraries are already installed.\n"]}],"source":["# List of required libraries\n","required_libraries = [\n","    'numpy',         \n","    'pandas',        \n","    'matplotlib',    \n","    'seaborn',       \n","    'scikit-learn',  \n","    'torch',         \n","    'transformers'   \n","]\n","\n","def install(package):\n","    \"\"\"Install the package using pip in a Jupyter Notebook.\"\"\"\n","    print(f\"Installing {package}...\")\n","    # Use the Jupyter magic command for installation\n","    get_ipython().system(f'pip install {package}')\n","\n","def check_libraries(libraries):\n","    \"\"\"Check if the libraries are installed and install them if necessary.\"\"\"\n","    missing_libraries = []\n","\n","    for library in libraries:\n","        try:\n","            __import__(library)\n","        except ImportError:\n","            missing_libraries.append(library)\n","        except Exception as e:\n","            # Captura outros erros que podem ocorrer durante a importação\n","            print(f\"Error importing {library}: {e}\")\n","            missing_libraries.append(library)\n","\n","    if missing_libraries:\n","        print(f\"The following libraries are missing: {', '.join(missing_libraries)}\")\n","        print(\"Starting installation...\")\n","\n","        installation_success = True  # Flag to track installation success\n","\n","        for library in missing_libraries:\n","            try:\n","                install(library)\n","                print(f\"{library} installed successfully.\")\n","            except Exception as e:\n","                print(f\"Failed to install {library}: {e}\")\n","                installation_success = False  # Mark as failed if there was an error\n","\n","        # Check again if the libraries were installed\n","        for library in missing_libraries:\n","            try:\n","                __import__(library)\n","            except ImportError:\n","                print(f\"Error: {library} was not installed correctly.\")\n","                installation_success = False  # Mark as failed if still missing\n","\n","        # Final message based on installation success\n","        if installation_success:\n","            print(\"All libraries were installed successfully.\")\n","        else:\n","            print(\"Some libraries were not installed correctly.\")\n","    else:\n","        print(\"All libraries are already installed.\")\n","\n","if __name__ == \"__main__\":\n","    check_libraries(required_libraries)"]},{"cell_type":"markdown","metadata":{},"source":["## Library Imports <a name=\"library-imports\"></a>\n","In this cell, we will import all the necessary libraries that we will use throughout the analysis. This includes libraries for data manipulation, visualization, and machine learning."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.072988Z","iopub.status.busy":"2024-09-30T20:45:20.072406Z","iopub.status.idle":"2024-09-30T20:45:20.089668Z","shell.execute_reply":"2024-09-30T20:45:20.088627Z","shell.execute_reply.started":"2024-09-30T20:45:20.072950Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\richena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# Standard Libraries\n","import warnings\n","from IPython.display import display\n","\n","# Data Science Libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Machine Learning Libraries\n","from sklearn.pipeline import make_pipeline\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","\n","# Deep Learning Libraries\n","import torch\n","from torch.utils.data import DataLoader\n","\n","# Transformers Library\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"]},{"cell_type":"markdown","metadata":{},"source":["## Data Loading <a name=\"data-loading\"></a>\n","Here, we will load the dataset containing information about Misconceptions in Mathematics and related factors. We will examine the structure of the data and check for any initial issues such as missing values."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.091513Z","iopub.status.busy":"2024-09-30T20:45:20.091098Z","iopub.status.idle":"2024-09-30T20:45:20.169530Z","shell.execute_reply":"2024-09-30T20:45:20.168566Z","shell.execute_reply.started":"2024-09-30T20:45:20.091425Z"},"trusted":true},"outputs":[],"source":["warnings.filterwarnings('ignore')\n","\n","# Reading the CSV files\n","train_df = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv')\n","test_df = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv')\n","miss_df = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv')\n","sample_df = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/sample_submission.csv')"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.172253Z","iopub.status.busy":"2024-09-30T20:45:20.171910Z","iopub.status.idle":"2024-09-30T20:45:20.185761Z","shell.execute_reply":"2024-09-30T20:45:20.184426Z","shell.execute_reply.started":"2024-09-30T20:45:20.172217Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Misconceptions in Mathematics Data:\n","   QuestionId  ConstructId                                      ConstructName  \\\n","0           0          856  Use the order of operations to carry out calcu...   \n","1           1         1612  Simplify an algebraic fraction by factorising ...   \n","2           2         2774            Calculate the range from a list of data   \n","3           3         2377  Recall and use the intersecting diagonals prop...   \n","4           4         3387  Substitute positive integer values into formul...   \n","\n","   SubjectId                                        SubjectName CorrectAnswer  \\\n","0         33                                             BIDMAS             A   \n","1       1077                    Simplifying Algebraic Fractions             D   \n","2        339  Range and Interquartile Range from a List of Data             B   \n","3         88                       Properties of Quadrilaterals             C   \n","4         67                          Substitution into Formula             A   \n","\n","                                        QuestionText            AnswerAText  \\\n","0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n","1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n","2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n","3  The angles highlighted on this rectangle with ...                  acute   \n","4  The equation \\( f=3 r^{2}+3 \\) is used to find...               \\( 30 \\)   \n","\n","              AnswerBText            AnswerCText             AnswerDText  \\\n","0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n","1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n","2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n","3                  obtuse       \\( 90^{\\circ} \\)  Not enough information   \n","4                \\( 27 \\)               \\( 51 \\)                \\( 24 \\)   \n","\n","   MisconceptionAId  MisconceptionBId  MisconceptionCId  MisconceptionDId  \n","0               NaN               NaN               NaN            1672.0  \n","1            2142.0             143.0            2142.0               NaN  \n","2            1287.0               NaN            1287.0            1073.0  \n","3            1180.0            1180.0               NaN            1180.0  \n","4               NaN               NaN               NaN            1818.0  \n"]}],"source":["# Display the first few rows of dataset to verify the reading\n","print(\"\\nMisconceptions in Mathematics Data:\")\n","print(train_df.head())"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.187554Z","iopub.status.busy":"2024-09-30T20:45:20.187180Z","iopub.status.idle":"2024-09-30T20:45:20.196362Z","shell.execute_reply":"2024-09-30T20:45:20.195269Z","shell.execute_reply.started":"2024-09-30T20:45:20.187508Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Shape of Combined Data: (1869, 15)\n"]}],"source":["# Using shape to check the dimensions of the combined DataFrame\n","print(\"\\nShape of Combined Data:\", train_df.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Initial Data Exploration <a name=\"initial-data-exploration\"></a>\n","In this section, we will conduct an exploratory data analysis (EDA) to gain a deeper understanding of our dataset. This analysis is crucial as it lays the foundation for the subsequent steps in our data cleaning and preparation process. We will examine various aspects of the data, including data types, summary statistics, and the presence of any missing values."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.198349Z","iopub.status.busy":"2024-09-30T20:45:20.197834Z","iopub.status.idle":"2024-09-30T20:45:20.215749Z","shell.execute_reply":"2024-09-30T20:45:20.214318Z","shell.execute_reply.started":"2024-09-30T20:45:20.198298Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing Values in Each Column:\n"," QuestionId            0\n","ConstructId           0\n","ConstructName         0\n","SubjectId             0\n","SubjectName           0\n","CorrectAnswer         0\n","QuestionText          0\n","AnswerAText           0\n","AnswerBText           0\n","AnswerCText           0\n","AnswerDText           0\n","MisconceptionAId    734\n","MisconceptionBId    751\n","MisconceptionCId    789\n","MisconceptionDId    832\n","dtype: int64\n"]}],"source":["# Check for missing values\n","missing_values = train_df.isnull().sum()\n","print(\"Missing Values in Each Column:\\n\", missing_values)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.217675Z","iopub.status.busy":"2024-09-30T20:45:20.217287Z","iopub.status.idle":"2024-09-30T20:45:20.227537Z","shell.execute_reply":"2024-09-30T20:45:20.226303Z","shell.execute_reply.started":"2024-09-30T20:45:20.217638Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Data Types of Each Column:\n"," QuestionId            int64\n","ConstructId           int64\n","ConstructName        object\n","SubjectId             int64\n","SubjectName          object\n","CorrectAnswer        object\n","QuestionText         object\n","AnswerAText          object\n","AnswerBText          object\n","AnswerCText          object\n","AnswerDText          object\n","MisconceptionAId    float64\n","MisconceptionBId    float64\n","MisconceptionCId    float64\n","MisconceptionDId    float64\n","dtype: object\n"]}],"source":["# Check data types\n","data_types = train_df.dtypes\n","print(\"\\nData Types of Each Column:\\n\", data_types)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.229377Z","iopub.status.busy":"2024-09-30T20:45:20.229019Z","iopub.status.idle":"2024-09-30T20:45:20.252902Z","shell.execute_reply":"2024-09-30T20:45:20.251864Z","shell.execute_reply.started":"2024-09-30T20:45:20.229340Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Corrected Data Types:\n","QuestionId          category\n","ConstructId         category\n","ConstructName         object\n","SubjectId           category\n","SubjectName           object\n","CorrectAnswer         object\n","QuestionText          object\n","AnswerAText           object\n","AnswerBText           object\n","AnswerCText           object\n","AnswerDText           object\n","MisconceptionAId    category\n","MisconceptionBId    category\n","MisconceptionCId    category\n","MisconceptionDId    category\n","dtype: object\n"]}],"source":["# Correcting data types\n","train_df['QuestionId'] = train_df['QuestionId'].astype('category')  # Ensure QuestionId is int\n","train_df['ConstructId'] = train_df['ConstructId'].astype('category')  # Ensure ConstructId is int\n","train_df['SubjectId'] = train_df['SubjectId'].astype('category')  # Ensure SubjectId is int\n","train_df['CorrectAnswer'] = train_df['CorrectAnswer'].astype(str)  # Ensure CorrectAnswer is str\n","train_df['ConstructName'] = train_df['ConstructName'].astype(str)  # Ensure ConstructName is str\n","train_df['SubjectName'] = train_df['SubjectName'].astype(str)  # Ensure SubjectName is str\n","train_df['QuestionText'] = train_df['QuestionText'].astype(str)  # Ensure QuestionText is str\n","train_df['AnswerAText'] = train_df['AnswerAText'].astype(str)  # Ensure AnswerAText is str\n","train_df['AnswerBText'] = train_df['AnswerBText'].astype(str)  # Ensure AnswerBText is str\n","train_df['AnswerCText'] = train_df['AnswerCText'].astype(str)  # Ensure AnswerCText is str\n","train_df['AnswerDText'] = train_df['AnswerDText'].astype(str)  # Ensure AnswerDText is str\n","\n","# For misconceptions, since they can be NaN, we can convert them to integers but also allow NaN values\n","train_df['MisconceptionAId'] = train_df['MisconceptionAId'].astype('category')  # Use 'Int64' to allow NaNs\n","train_df['MisconceptionBId'] = train_df['MisconceptionBId'].astype('category')  # Use 'Int64' to allow NaNs\n","train_df['MisconceptionCId'] = train_df['MisconceptionCId'].astype('category')  # Use 'Int64' to allow NaNs\n","train_df['MisconceptionDId'] = train_df['MisconceptionDId'].astype('category')  # Use 'Int64' to allow NaNs\n","\n","# Check the corrected data types\n","print(\"\\nCorrected Data Types:\")\n","print(train_df.dtypes)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation <a name=\"data-preparation\"></a>\n","In order to build effective machine learning models for our NLP competition, we must first ensure that our data is prepared thoroughly. The data preparation process is critical for achieving optimal model performance and involves several key steps.\n","\n","First, we need to handle any missing values that may exist in our dataset. This is essential to prevent any disruptions in the training process and to ensure that our model can learn from complete data. Next, we will encode categorical variables, which allows our machine learning algorithms to interpret the data correctly and make accurate predictions.\n","\n","Additionally, we will split the dataset into training and testing sets. This division is crucial as it enables us to evaluate our model's performance on unseen data, helping us avoid overfitting and ensuring that our model generalizes well.\n","\n","We will also analyze the distribution of question lengths to understand the complexity of the data we are working with. Understanding this distribution can provide insights into how to preprocess our text data effectively. Cleaning the text data is another vital step, as it enhances the quality of the input provided to the model, ultimately leading to improved predictions\n","\n","Below is the code that implements these data preparation steps, creating prediction and test dataframes from our original dataset, and concatenating the relevant texts to form a complete input for our models."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.254547Z","iopub.status.busy":"2024-09-30T20:45:20.254210Z","iopub.status.idle":"2024-09-30T20:45:20.570259Z","shell.execute_reply":"2024-09-30T20:45:20.569164Z","shell.execute_reply.started":"2024-09-30T20:45:20.254510Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>QuestionId</th>\n","      <th>Answer</th>\n","      <th>QuestionText</th>\n","      <th>MisconceptionId</th>\n","      <th>AnswerText</th>\n","      <th>QuestionAnswer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n","      <td>1672.0</td>\n","      <td>Does not need brackets</td>\n","      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","      <td>2142.0</td>\n","      <td>\\( m+1 \\)</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","      <td>143.0</td>\n","      <td>\\( m+2 \\)</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>C</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","      <td>2142.0</td>\n","      <td>\\( m-1 \\)</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n","      <td>1287.0</td>\n","      <td>Only\\nTom</td>\n","      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5602</th>\n","      <td>1867</td>\n","      <td>C</td>\n","      <td>Tom and Katie are discussing congruence and si...</td>\n","      <td>2312.0</td>\n","      <td>Both Tom and Katie</td>\n","      <td>Tom and Katie are discussing congruence and si...</td>\n","    </tr>\n","    <tr>\n","      <th>5603</th>\n","      <td>1867</td>\n","      <td>D</td>\n","      <td>Tom and Katie are discussing congruence and si...</td>\n","      <td>2312.0</td>\n","      <td>Neither is correct</td>\n","      <td>Tom and Katie are discussing congruence and si...</td>\n","    </tr>\n","    <tr>\n","      <th>5604</th>\n","      <td>1868</td>\n","      <td>A</td>\n","      <td>Jo and Paul are arguing about how to fully des...</td>\n","      <td>801.0</td>\n","      <td>Only\\nJo</td>\n","      <td>Jo and Paul are arguing about how to fully des...</td>\n","    </tr>\n","    <tr>\n","      <th>5605</th>\n","      <td>1868</td>\n","      <td>C</td>\n","      <td>Jo and Paul are arguing about how to fully des...</td>\n","      <td>801.0</td>\n","      <td>Both Jo and Paul</td>\n","      <td>Jo and Paul are arguing about how to fully des...</td>\n","    </tr>\n","    <tr>\n","      <th>5606</th>\n","      <td>1868</td>\n","      <td>D</td>\n","      <td>Jo and Paul are arguing about how to fully des...</td>\n","      <td>95.0</td>\n","      <td>Neither is correct</td>\n","      <td>Jo and Paul are arguing about how to fully des...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4370 rows × 6 columns</p>\n","</div>"],"text/plain":["      QuestionId Answer                                       QuestionText  \\\n","2              0      D  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...   \n","3              1      A  Simplify the following, if possible: \\( \\frac{...   \n","4              1      B  Simplify the following, if possible: \\( \\frac{...   \n","5              1      C  Simplify the following, if possible: \\( \\frac{...   \n","6              2      A  Tom and Katie are discussing the \\( 5 \\) plant...   \n","...          ...    ...                                                ...   \n","5602        1867      C  Tom and Katie are discussing congruence and si...   \n","5603        1867      D  Tom and Katie are discussing congruence and si...   \n","5604        1868      A  Jo and Paul are arguing about how to fully des...   \n","5605        1868      C  Jo and Paul are arguing about how to fully des...   \n","5606        1868      D  Jo and Paul are arguing about how to fully des...   \n","\n","      MisconceptionId              AnswerText  \\\n","2              1672.0  Does not need brackets   \n","3              2142.0               \\( m+1 \\)   \n","4               143.0               \\( m+2 \\)   \n","5              2142.0               \\( m-1 \\)   \n","6              1287.0               Only\\nTom   \n","...               ...                     ...   \n","5602           2312.0      Both Tom and Katie   \n","5603           2312.0      Neither is correct   \n","5604            801.0                Only\\nJo   \n","5605            801.0        Both Jo and Paul   \n","5606             95.0      Neither is correct   \n","\n","                                         QuestionAnswer  \n","2     \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \n","3     Simplify the following, if possible: \\( \\frac{...  \n","4     Simplify the following, if possible: \\( \\frac{...  \n","5     Simplify the following, if possible: \\( \\frac{...  \n","6     Tom and Katie are discussing the \\( 5 \\) plant...  \n","...                                                 ...  \n","5602  Tom and Katie are discussing congruence and si...  \n","5603  Tom and Katie are discussing congruence and si...  \n","5604  Jo and Paul are arguing about how to fully des...  \n","5605  Jo and Paul are arguing about how to fully des...  \n","5606  Jo and Paul are arguing about how to fully des...  \n","\n","[4370 rows x 6 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["def create_prediction_dataframe(df):\n","    # Create a list to store the predictions\n","    pred_list = []\n","\n","    # Add the questions and answers\n","    for index, row in df.iterrows():\n","        for answer in ['A', 'B', 'C', 'D']:\n","            # Check if the current answer is equal to the correct answer\n","            if answer != row['CorrectAnswer']:\n","                pred_list.append({\n","                    'QuestionId': row['QuestionId'],\n","                    'Answer': answer,\n","                    'QuestionText': row['QuestionText'],\n","                    'MisconceptionId': row[f'Misconception{answer}Id'],\n","                    'AnswerText': row[f'Answer{answer}Text'] \n","                })\n","\n","    # Create a dataframe from the list\n","    pred_data = pd.DataFrame(pred_list)\n","    return pred_data\n","\n","\n","def create_test_dataframe(df):\n","    # Create a list to store the test data\n","    test_list = []\n","\n","    # Add the questions and answers\n","    for index, row in df.iterrows():\n","        for answer in ['A', 'B', 'C', 'D']:\n","            test_list.append({\n","                'QuestionId': row['QuestionId'],\n","                'Answer': answer,\n","                'QuestionText': row['QuestionText'],\n","                'AnswerText': row[f'Answer{answer}Text'] \n","            })\n","\n","    # Create a dataframe from the list\n","    test_data = pd.DataFrame(test_list)\n","    return test_data\n","\n","\n","# Create Prediction DataFrame for the training set\n","train_pred_data = create_prediction_dataframe(train_df)\n","\n","train_pred_data['QuestionAnswer'] = train_pred_data['QuestionText'] + train_pred_data['AnswerText']\n","train_pred_data.dropna(inplace=True)\n","\n","test_pred_data = create_test_dataframe(test_df)\n","\n","test_pred_data['QuestionAnswer'] = test_pred_data['QuestionText'] + test_pred_data['AnswerText']\n","\n","# Display the resulting DataFrames\n","display(train_pred_data)"]},{"cell_type":"markdown","metadata":{},"source":["## Modeling <a name=\"modeling\"></a>\n","In this section, we will build and evaluate machine learning models aimed at predicting instances of cyberbullying based on the textual content of tweets. Our primary objective is to select suitable algorithms, fit them to our training data, and assess their performance using a variety of metrics.\n","\n","To initiate our modeling process, we first load and save a pre-trained BERT tokenizer and model. These components are essential for processing the textual data and transforming it into a format suitable for our machine learning algorithms."]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.573787Z","iopub.status.busy":"2024-09-30T20:45:20.573390Z","iopub.status.idle":"2024-09-30T20:45:20.579087Z","shell.execute_reply":"2024-09-30T20:45:20.577891Z","shell.execute_reply.started":"2024-09-30T20:45:20.573748Z"},"trusted":true},"outputs":[],"source":["# # Load and save locally\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=miss_df['MisconceptionId'].nunique())\n","\n","# # Save locally\n","# tokenizer.save_pretrained('./local_bert')\n","# model.save_pretrained('./local_bert')"]},{"cell_type":"markdown","metadata":{},"source":["Next, we will load our training data, which consists of tweet texts and their corresponding labels indicating instances of cyberbullying. We split this data into training and validation sets to ensure that we can evaluate our model's performance on unseen data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the data\n","X = train_pred_data['QuestionAnswer']\n","y = train_pred_data['MisconceptionId'].astype(int)  # You can use a multi-label approach\n","\n","# Split into training and validation\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["After that, we load the BERT tokenizer and model from our local directory to prepare for the tokenization of our data. Tokenization is a crucial step that converts the raw text into numerical representations that the model can understand."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the BERT tokenizer and model from local directory\n","tokenizer = BertTokenizer.from_pretrained('./local_bert')\n","model = BertForSequenceClassification.from_pretrained('./local_bert', num_labels=miss_df['MisconceptionId'].nunique())"]},{"cell_type":"markdown","metadata":{},"source":["We then proceed to tokenize our training and validation datasets, applying truncation and padding to ensure uniform input sizes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tokenization of the data\n","train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n","val_encodings = tokenizer(list(X_val), truncation=True, padding=True, max_length=128)"]},{"cell_type":"markdown","metadata":{},"source":["To facilitate the training process, we create a custom dataset class that transforms our tokenized data into PyTorch tensors, which are necessary for model training."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create PyTorch tensors\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels.to_numpy()  # Convert to NumPy array\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])  # Use idx directly\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = CustomDataset(train_encodings, y_train)\n","val_dataset = CustomDataset(val_encodings, y_val)"]},{"cell_type":"markdown","metadata":{},"source":["Next, we set up the training configurations, specifying parameters such as batch size, number of epochs, and logging options. These configurations will guide the training process."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Training configurations\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    fp16=True,\n","    num_train_epochs=12,\n","    gradient_accumulation_steps=2,  # Para simular um tamanho de lote maior\n","    logging_dir='./logs',\n","    report_to=[\"none\"],\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Finally, we initialize the Trainer class with our model and training arguments, and we proceed to train the model. After training, we evaluate its performance on the validation set."]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T20:45:20.580702Z","iopub.status.busy":"2024-09-30T20:45:20.580352Z","iopub.status.idle":"2024-10-01T03:58:51.595823Z","shell.execute_reply":"2024-10-01T03:58:51.593644Z","shell.execute_reply.started":"2024-09-30T20:45:20.580655Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [660/660 7:09:53, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>6.717600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [28/28 02:43]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 6.938859939575195,\n"," 'eval_runtime': 170.062,\n"," 'eval_samples_per_second': 5.139,\n"," 'eval_steps_per_second': 0.165,\n"," 'epoch': 12.0}"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# Training\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")\n","\n","trainer.train()\n","\n","# Evaluation\n","trainer.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["By executing the above steps, we will successfully develop and evaluate our machine learning models, enabling us to predict instances of cyberbullying based on the textual content of tweets. This process not only enhances our understanding of the data but also provides valuable insights into the effectiveness of our chosen algorithm"]},{"cell_type":"markdown","metadata":{},"source":["## Model Evaluation <a name=\"model-evaluation\"></a>\n","After building our models, it is crucial to evaluate their performance to determine how well they can predict instances of cyberbullying based on the textual content of tweets. In this section, we will assess each model using various metrics, including accuracy, precision, recall, and F1-score. We will compare the predictions against the actual outcomes to gain insights into the effectiveness of our models."]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation Steps\n","- Extract Predictions: We will first extract the question-answer pairs from the test dataset and create a unique identifier for each question-answer combination.\n","- Tokenization: The test dataset will be tokenized using the same BERT tokenizer that we used for training, ensuring consistency in input format.\n","- Custom Dataset Class: We will define a custom dataset class for the test data to facilitate batch processing during evaluation.\n","- DataLoader: A DataLoader will be created for the test dataset to allow for easy iteration through the data in batches.\n","- Make Predictions: We will use the trained model to make predictions on the test dataset, retrieving the top predictions for each input.\n","- Format Predictions: Finally, we will format the predictions for submission and save them in a CSV file.\n","\n","Below is the code that implements these evaluation steps:"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T03:58:51.599872Z","iopub.status.busy":"2024-10-01T03:58:51.599370Z","iopub.status.idle":"2024-10-01T03:59:14.065678Z","shell.execute_reply":"2024-10-01T03:59:14.064637Z","shell.execute_reply.started":"2024-10-01T03:58:51.599821Z"},"trusted":true},"outputs":[],"source":["# Extract question-answer pairs from the test dataset\n","question_answers = test_pred_data['QuestionAnswer']\n","\n","# Create 'question_id' by combining 'QuestionId' and 'Answer'\n","test_pred_data['question_id'] = test_pred_data['QuestionId'].astype(str) + '_' + test_pred_data['Answer'].astype(str)\n","\n","# Tokenize the test dataset\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","test_encodings = tokenizer(list(question_answers), truncation=True, padding=True, max_length=128)\n","\n","# Custom dataset class for the test data\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        # Convert each encoding to a tensor\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        return item\n","\n","    def __len__(self):\n","        # Return the number of input samples\n","        return len(self.encodings['input_ids'])\n","\n","# Create DataLoader for the test dataset\n","test_dataset = CustomDataset(test_encodings)\n","test_loader = DataLoader(test_dataset, batch_size=8)\n","\n","# Make predictions\n","predictions = []\n","question_ids = []  # Store corresponding question IDs\n","with torch.no_grad():  # Disable gradient calculation during evaluation\n","    for batch_idx, batch in enumerate(test_loader):\n","        outputs = model(**batch)\n","        logits = outputs.logits\n","        # Get probabilities using softmax\n","        probs = torch.softmax(logits, dim=1)\n","        # Retrieve indices of the top 25 predictions\n","        top_k = torch.topk(probs, k=25, dim=1).indices  # shape: (batch_size, 25)\n","        predictions.append(top_k)\n","\n","        # Collect corresponding question IDs for each batch\n","        start_idx = batch_idx * test_loader.batch_size\n","        end_idx = start_idx + len(batch['input_ids'])\n","        question_ids.extend(test_pred_data['question_id'].iloc[start_idx:end_idx])\n","\n","# Format the predictions for submission\n","final_predictions = []\n","for batch_preds in predictions:\n","    for pred in batch_preds:\n","        # Append the top 25 misconception IDs as a space-separated string\n","        final_predictions.append(' '.join(map(str, pred.numpy())))\n","\n","# Create a DataFrame for the submission file\n","submission_df = pd.DataFrame({\n","    'QuestionId_Answer': question_ids,\n","    'MisconceptionId': final_predictions\n","})\n","\n","# Save the DataFrame as a CSV file\n","submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["By following the steps outlined above, we can effectively evaluate our models and produce a submission file containing the top predictions for each question-answer pair. This evaluation process allows us to quantify the performance of our models and make necessary adjustments or improvements based on the results. The metrics derived from the evaluation will provide valuable insights into the model's strengths and weaknesses in predicting instances of cyberbullying."]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion and Next Steps <a name=\"conclusion-and-next-steps\"></a>\n","In this project, we developed machine learning models to detect various forms of cyberbullying on Twitter. Our analysis revealed significant insights into the prevalence of different types of cyberbullying, with religion and age being the most common categories. The models achieved varying levels of accuracy, with XGBoost performing the best at 82.96%."]},{"cell_type":"markdown","metadata":{},"source":["### Recommendations:\n","- Implement Monitoring Tools: Social media platforms should consider implementing automated monitoring tools to detect and flag harmful content in real-time.\n","- Educational Initiatives: Schools and organizations should promote awareness programs about the effects of cyberbullying and encourage positive online behavior."]},{"cell_type":"markdown","metadata":{},"source":["### Future Work:\n","- Real-Time Detection: Explore the implementation of the model as a real-time detection system for social media platforms.\n","- Deep Learning Approaches: Investigate the use of deep learning techniques to improve accuracy in text classification tasks."]},{"cell_type":"markdown","metadata":{},"source":["By continuing to refine our models and approaches, we can contribute to creating a safer online environment for all users."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9551816,"sourceId":82695,"sourceType":"competition"}],"dockerImageVersionId":30775,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
